{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db99f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests_html import HTMLSession\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4c05d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my wbsites\n",
    "imoVirtual_apartaments_cascais = 'https://www.imovirtual.com/pt/resultados/comprar/apartamento/lisboa/cascais?limit=72&ownerTypeSingleSelect=ALL&priceMax=240000&roomsNumber=%5BTHREE%2CFOUR%2CFIVE%2CSIX_OR_MORE%5D&by=DEFAULT&direction=DESC&viewType=listing'\n",
    "imoVirtual_houses_cascais = 'https://www.imovirtual.com/pt/resultados/comprar/moradia/lisboa/cascais?ownerTypeSingleSelect=ALL&roomsNumber=%5BTHREE%2CFOUR%2CFIVE%2CSIX_OR_MORE%5D&priceMax=240000&by=DEFAULT&direction=DESC&viewType=listing'\n",
    "imoVirtual_apartaments_oeiras = 'https://www.imovirtual.com/pt/resultados/comprar/apartamento/lisboa/oeiras?limit=72&ownerTypeSingleSelect=ALL&priceMax=240000&roomsNumber=%5BTHREE%2CFOUR%2CFIVE%2CSIX_OR_MORE%5D&by=DEFAULT&direction=DESC&viewType=listing'\n",
    "imoVirtual_houses_oeiras = 'https://www.imovirtual.com/pt/resultados/comprar/moradia/lisboa/oeiras?limit=36&ownerTypeSingleSelect=ALL&priceMax=240000&roomsNumber=%5BTHREE%2CFOUR%2CFIVE%2CSIX_OR_MORE%5D&by=DEFAULT&direction=DESC&viewType=listing'\n",
    "idealista = 'https://www.idealista.pt/comprar-casas/cascais/com-preco-max_240000,t2,t3,t4-t5/?ordem=atualizado-desc'\n",
    "remax_cascais = 'https://www.remax.pt/comprar?searchQueryState=%7B%22regionName%22:%22cascais%22,%22businessType%22:1,%22page%22:1,%22regionID%22:%22%22,%22regionType%22:%22%22,%22sort%22:%7B%22fieldToSort%22:%22PublishDate%22,%22order%22:1%7D,%22mapIsOpen%22:false,%22price%22:%7B%22min%22:null,%22max%22:240000%7D,%22mapScroll%22:false,%22rooms%22:2%7D'\n",
    "remax_oeiras = 'https://www.remax.pt/comprar?searchQueryState=%7B%22regionName%22:%22Oeiras%22,%22businessType%22:1,%22page%22:1,%22regionID%22:%22541%22,%22regionType%22:%22Region2ID%22,%22sort%22:%7B%22fieldToSort%22:%22PublishDate%22,%22order%22:1%7D,%22mapIsOpen%22:false,%22listingClass%22:1,%22price%22:%7B%22min%22:null,%22max%22:240000%7D,%22mapScroll%22:false,%22rooms%22:2,%22listingTypes%22:%5B%5D,%22prn%22:%22Oeiras,%20Lisboa%22,%22regionCoordinates%22:%7B%22latitude%22:38.7170951617666,%22longitude%22:-9.269621200241543%7D,%22regionZoom%22:12%7D'\n",
    "era_link = 'https://www.era.pt/comprar?ob=1&tp=1,2&lc=11-05,11-10&nqMin=2&nqMax=5&pvMax=250000&page=1&ord=3'\n",
    "\n",
    "#webiste lists\n",
    "imoVirtual_list = [imoVirtual_apartaments_cascais, imoVirtual_houses_cascais, imoVirtual_apartaments_oeiras, imoVirtual_houses_oeiras]\n",
    "remax_list = [remax_cascais, remax_oeiras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb69f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imoVirtual (site_url):\n",
    "    \"\"\"Provide the Imovirtual link and it will add the houses info to my excel: houses.xlsx\n",
    "    The excel file must be in the same folder of the code\"\"\"\n",
    "    \n",
    "    #use headers to mimic a real website\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36',\n",
    "        'Referer': 'https://www.google.com/',\n",
    "    }\n",
    "\n",
    "    #request\n",
    "    r = requests.get(site_url, headers=headers, verify=False) #using verify=False is not the best practice\n",
    "    if r.status_code == 200:\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        #get houses information\n",
    "        sections = soup.find_all('section') # division for all the houses\n",
    "        #loop for each house\n",
    "        for section in sections:\n",
    "            try:\n",
    "                name = section.find('p', class_=\"css-u3orbr e1g5xnx10\").text\n",
    "                zone = section.find('p', class_=\"css-42r2ms eejmx80\").text\n",
    "                house_price = section.find('span', class_='css-2bt9f1 evk7nst0').text\n",
    "                url = f\"https://www.imovirtual.com{section.find('a')['href']}\"\n",
    "                #unpack general info\n",
    "                dd_elements = section.find_all('dd')\n",
    "                values = [dd.get_text() for dd in dd_elements]\n",
    "                bedrooms = values[0]\n",
    "                area = values[1]\n",
    "                description = section.find('div', class_=\"css-1b63dzw e1uq9mc93\").text\n",
    "                #create a list to save my house values\n",
    "                info_list = [name, zone, house_price, url, bedrooms, area, description]\n",
    "            except:\n",
    "                print(\"Could not get house information.\")\n",
    "            #Load excel file\n",
    "            workbook = load_workbook(filename='houses.xlsx')\n",
    "            #Load sheet by index\n",
    "            sheet = workbook.worksheets[0]\n",
    "            number_of_rows = sheet.max_row #Used to calculate the last row of the table\n",
    "            #check if house is in the excel based on the url befor add it\n",
    "            found = False\n",
    "            for cell in sheet.iter_rows(min_row=1, max_row=number_of_rows, min_col=4, max_col=4):\n",
    "                for c in cell:\n",
    "                    if c.value == url:\n",
    "                        found = True #found my string (house url) in the excel\n",
    "                        break\n",
    "            if found == False: # this means the house url is not in the excel\n",
    "                #loop to add values to excel\n",
    "                for numb in range(sheet.max_column): \n",
    "                    #add value to a cell\n",
    "                    sheet.cell(row=number_of_rows + 1, column=numb+1).value = info_list[numb]\n",
    "                    #Apply color to new rows\n",
    "                    yellow_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')\n",
    "                    sheet.cell(row=number_of_rows + 1, column=numb+1).fill = yellow_fill   \n",
    "            #save the file\n",
    "            workbook.save(filename='houses.xlsx')         \n",
    "    else:\n",
    "        print(\"Not possible to get website.\")\n",
    "    print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa92c9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmaci7rx\\AppData\\Local\\miniforge3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.imovirtual.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get house information.\n",
      "Could not get house information.\n",
      "FINISHED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmaci7rx\\AppData\\Local\\miniforge3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.imovirtual.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get house information.\n",
      "Could not get house information.\n",
      "FINISHED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmaci7rx\\AppData\\Local\\miniforge3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.imovirtual.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get house information.\n",
      "Could not get house information.\n",
      "FINISHED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmaci7rx\\AppData\\Local\\miniforge3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.imovirtual.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get house information.\n",
      "Could not get house information.\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "for link in imoVirtual_list:\n",
    "    imoVirtual(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52eda51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remaxHouses (my_url):\n",
    "    # Set up Chrome options for headless mode\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Ensure GUI is off\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    # Automatically manage the WebDriver\n",
    "    #driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    # Run this when you dont need to manage any webdriver update\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # Open a URL\n",
    "    driver.get(my_url)\n",
    "    sleep(4) # wait for the page to load\n",
    "\n",
    "    # Get page content\n",
    "    page_content = driver.page_source\n",
    "    # parse HTML content with Beautifull Soup\n",
    "    soup = BeautifulSoup(page_content,'html.parser')\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    #Get house information using Beautifull Soup\n",
    "    house_div = soup.find_all('div', class_=\"col-12 col-sm-6 col-md-6 col-lg-4 col-xl-3 result\")\n",
    "    #Loop to get information of all the houses\n",
    "    for house in house_div:\n",
    "        name = f'{house.find(\"li\", class_=\"listing-type\").text.strip()} Remax'\n",
    "        zone = house.find('h2', class_=\"listing-address\").find('span').text.strip()\n",
    "        price = house.find('p', class_=\"listing-price\").text.strip()\n",
    "        url = f\"https://www.remax.pt{house.find('a')['href']}\"\n",
    "        bedrooms = str(\"T\" + house.find('li', class_=\"listing-bedroom\").text.strip())\n",
    "        area = house.find('li', class_=\"listing-area\").text.strip()\n",
    "        description = house.find('span', id=\"listing-description-tags\").text.replace(\"-\", \" \")\n",
    "        #create a list to save my house values\n",
    "        info_list = [name, zone, price, url, bedrooms, area, description]\n",
    "        #Load excel file\n",
    "        workbook = load_workbook(filename='houses.xlsx')\n",
    "        #Load sheet by index\n",
    "        sheet = workbook.worksheets[0]\n",
    "        number_of_rows = sheet.max_row #Used to calculate the last row of the table\n",
    "        #check if house is in the excel based on the url befor add it\n",
    "        found = False\n",
    "        for cell in sheet.iter_rows(min_row=1, max_row=number_of_rows, min_col=4, max_col=4):\n",
    "            for c in cell:\n",
    "                if c.value == url:\n",
    "                    found = True #found my string (house url) in the excel\n",
    "                    break\n",
    "        if found == False: # this means the house url is not in the excel\n",
    "            #loop to add values to excel\n",
    "            for numb in range(sheet.max_column): \n",
    "                #add value to a cell\n",
    "                sheet.cell(row=number_of_rows + 1, column=numb+1).value = info_list[numb]\n",
    "                #Apply color to new rows\n",
    "                yellow_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')\n",
    "                sheet.cell(row=number_of_rows + 1, column=numb+1).fill = yellow_fill   \n",
    "        #save the file\n",
    "        workbook.save(filename='houses.xlsx')\n",
    "\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7509bc4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "for link in remax_list:\n",
    "    remaxHouses(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "477acae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idealista_houses(my_url):\n",
    "    #It is not possible to run in headless mode because of captcha\n",
    "\n",
    "    # Automatically manage the WebDriver\n",
    "    #driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    # Run this when you dont need to manage any webdriver update\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # Open a URL\n",
    "    driver.get(my_url)\n",
    "    sleep(20) # wait for the page to load\n",
    "\n",
    "    # Get page content\n",
    "    page_content = driver.page_source\n",
    "    # parse HTML content with Beautifull Soup\n",
    "    soup = BeautifulSoup(page_content,'html.parser')\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    #Get house information using Beautifull Soup\n",
    "    house_div = soup.find('div', class_=\"item-info-container\")\n",
    "    #Loop to get information of all the houses\n",
    "    for house in house_div:\n",
    "        name = house.find('a')['title']\n",
    "        #to get the zone first clean some text spliting and slicing the string and next joining it\n",
    "        zone_word_list = house.find('a')['title'].split()[3:]\n",
    "        zone = \" \".join(zone_word_list)\n",
    "        price = house.find('span', class_=\"item-price h2-simulated\").text\n",
    "        url = f'https://www.idealista.pt{house.find(\"a\")[\"href\"]}'\n",
    "        #bedroom and area are in the same tag. Use find_all and use the slice of the list\n",
    "        bedrooms = house.find_all('span', class_=\"item-detail\")[0].text.strip()\n",
    "        area = house.find_all('span', class_=\"item-detail\")[1].text.strip().replace(\" área bruta\", \"\")\n",
    "        description = house.find('div', class_=\"item-description description\").text.strip()\n",
    "        #create a list to save my house values\n",
    "        info_list = [name, zone, price, url, bedrooms, area, description]\n",
    "        #Load excel file\n",
    "        workbook = load_workbook(filename='houses.xlsx')\n",
    "        #Load sheet by index\n",
    "        sheet = workbook.worksheets[0]\n",
    "        number_of_rows = sheet.max_row #Used to calculate the last row of the table\n",
    "        #check if house is in the excel based on the url befor add it\n",
    "        found = False\n",
    "        for cell in sheet.iter_rows(min_row=1, max_row=number_of_rows, min_col=4, max_col=4):\n",
    "            for c in cell:\n",
    "                if c.value == url:\n",
    "                    found = True #found my string (house url) in the excel\n",
    "                    break\n",
    "        if found == False: # this means the house url is not in the excel\n",
    "            #loop to add values to excel\n",
    "            for numb in range(sheet.max_column): \n",
    "                #add value to a cell\n",
    "                sheet.cell(row=number_of_rows + 1, column=numb+1).value = info_list[numb]\n",
    "                #Apply color to new rows\n",
    "                yellow_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')\n",
    "                sheet.cell(row=number_of_rows + 1, column=numb+1).fill = yellow_fill   \n",
    "        #save the file\n",
    "        workbook.save(filename='houses.xlsx')\n",
    "\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39b86cf7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43midealista_houses\u001b[49m\u001b[43m(\u001b[49m\u001b[43midealista\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[58], line 25\u001b[0m, in \u001b[0;36midealista_houses\u001b[1;34m(my_url)\u001b[0m\n\u001b[0;32m     23\u001b[0m house_div \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem-info-container\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#Loop to get information of all the houses\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m house \u001b[38;5;129;01min\u001b[39;00m house_div:\n\u001b[0;32m     26\u001b[0m     name \u001b[38;5;241m=\u001b[39m house_div\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m#to get the zone first clean some text spliting and slicing the string and next joining it\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    idealista_houses(idealista)\n",
    "except:\n",
    "    print(\"Website block driver.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b1036641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def era_houses(my_url):\n",
    "    # Set up Chrome options for headless mode\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Ensure GUI is off\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    # Automatically manage the WebDriver\n",
    "    #driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    # Run this when you dont need to manage any webdriver update\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # Open a URL\n",
    "    driver.get(my_url)\n",
    "    sleep(5) # wait for the page to load\n",
    "\n",
    "    # Get page content\n",
    "    page_content = driver.page_source\n",
    "    # parse HTML content with Beautifull Soup\n",
    "    soup = BeautifulSoup(page_content,'html.parser')\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    #Get house information using Beautifull Soup\n",
    "    house_div = soup.find_all(class_=\"content p-3\")\n",
    "    #Loop to get information of all the houses\n",
    "    for house in house_div:\n",
    "        name = f'{house_div.find(\"p\", class_=\"property-type d-block mb-1\").text} ERA'\n",
    "        zone = house.find('div', class_=\"col-12 location\").text\n",
    "        price = house.find('p', class_=\"price-value\").text\n",
    "        url = house.find('a')['href']\n",
    "        bedrooms = f'T{house_div.find_all(\"span\", class_=\"d-inline-flex\")[0].text}'\n",
    "        area = house_div.find_all(\"span\", class_=\"d-inline-flex\")[3].text\n",
    "        description = \"No description\"\n",
    "        #create a list to save my house values\n",
    "        info_list = [name, zone, price, url, bedrooms, area, description]\n",
    "        #Load excel file\n",
    "        workbook = load_workbook(filename='houses.xlsx')\n",
    "        #Load sheet by index\n",
    "        sheet = workbook.worksheets[0]\n",
    "        number_of_rows = sheet.max_row #Used to calculate the last row of the table\n",
    "        #check if house is in the excel based on the url befor add it\n",
    "        found = False\n",
    "        for cell in sheet.iter_rows(min_row=1, max_row=number_of_rows, min_col=4, max_col=4):\n",
    "            for c in cell:\n",
    "                if c.value == url:\n",
    "                    found = True #found my string (house url) in the excel\n",
    "                    break\n",
    "        if found == False: # this means the house url is not in the excel\n",
    "            #loop to add values to excel\n",
    "            for numb in range(sheet.max_column): \n",
    "                #add value to a cell\n",
    "                sheet.cell(row=number_of_rows + 1, column=numb+1).value = info_list[numb]\n",
    "                #Apply color to new rows\n",
    "                yellow_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')\n",
    "                sheet.cell(row=number_of_rows + 1, column=numb+1).fill = yellow_fill   \n",
    "        #save the file\n",
    "        workbook.save(filename='houses.xlsx')\n",
    "\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "59b4e502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "era_houses(era_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
